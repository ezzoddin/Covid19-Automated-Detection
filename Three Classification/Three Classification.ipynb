{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "github.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BffdfxAtP_k7"
      },
      "source": [
        "# Import All we Need"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlWGPcUHef0x"
      },
      "source": [
        "# filter warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
        "\n",
        "# keras imports \n",
        "from keras.applications.densenet import DenseNet169 , preprocess_input\n",
        "\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.models import model_from_json\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "# other imports\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import seaborn as sns\n",
        "\n",
        "import pickle\n",
        "import glob\n",
        "import cv2\n",
        "import h5py\n",
        "import os\n",
        "import json\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Edp479QOQRKm"
      },
      "source": [
        "# load the user configs , from config.json\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IlLdPuxekYx"
      },
      "source": [
        "# load the user configs\n",
        "\n",
        "# use your own path\n",
        "with open('/content/drive/MyDrive/covid19/config/config.json') as f:    \n",
        "  config = json.load(f)\n",
        "\n",
        "\n",
        "# config variables\n",
        "model_name      = config[\"model\"]\n",
        "weights         = config[\"weights\"]\n",
        "include_top     = config[\"include_top\"]\n",
        "train_path      = config[\"train_path\"]\n",
        "features_path   = config[\"features_path\"]\n",
        "labels_path     = config[\"labels_path\"]\n",
        "test_size       = config[\"test_size\"]\n",
        "model_path      = config[\"model_path\"]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqJkdvQLQThO"
      },
      "source": [
        "# Use DenseNet169 as Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF3mOcKOQUuQ"
      },
      "source": [
        "\n",
        "# DenseNet169 as model \n",
        "\n",
        "if model_name == \"DenseNet169\":\n",
        "  base_model = DenseNet169(include_top=include_top, weights=weights, input_tensor=Input(shape=(224,224,3)), input_shape=(224,224,3), pooling=\"avg\")\n",
        "  model = Model(base_model.input, base_model.get_layer('avg_pool').output)\n",
        "  image_size = (224, 224)\n",
        "\n",
        "else:\n",
        "  base_mode = none\n",
        "\n",
        "\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAq1kJ1DRKc1"
      },
      "source": [
        "# encoding labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3iqKA5dgdOL"
      },
      "source": [
        "# path to training dataset\n",
        "train_labels = os.listdir(train_path)\n",
        "\n",
        "# encode the labels\n",
        "print(\"[INFO] encoding labels...\")\n",
        "le = LabelEncoder()\n",
        "le.fit([tl for tl in train_labels])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2Zh28xiROTg"
      },
      "source": [
        "\n",
        "# Feature Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itCKaNnrROpc"
      },
      "source": [
        "# variables to hold features and labels\n",
        "features = []\n",
        "labels   = []\n",
        "\n",
        "\n",
        "# loop over all the labels in the folder\n",
        "count = 1\n",
        "for i, label in enumerate(train_labels):\n",
        "  cur_path = train_path + \"/\" + label\n",
        "  count = 1\n",
        "  for image_path in glob.glob(cur_path + \"/*\"):\n",
        "    img = image.load_img(image_path, target_size=image_size)\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    feature = model.predict(x)\n",
        "    flat = feature.flatten()\n",
        "    features.append(flat)\n",
        "    labels.append(label)\n",
        "    print(\"[INFO] processed - \" + str(count))\n",
        "    count += 1\n",
        "  print(\"[INFO] completed label - \" + label)\n",
        "\n",
        "# encode the labels using LabelEncoder\n",
        "le = LabelEncoder()\n",
        "le_labels = le.fit_transform(labels)\n",
        "\n",
        "# get the shape of  training labels\n",
        "print(\"[STATUS] training labels: {}\".format(le_labels))\n",
        "print(\"[STATUS] training labels shape: {}\".format(le_labels.shape))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yfQV1IvRtpN"
      },
      "source": [
        "# save features and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJgLrgv5Rtz5",
        "outputId": "e7848604-70ea-42fb-dbaa-623368d2dcd4"
      },
      "source": [
        "# save features and labels\n",
        "h5f_data = h5py.File(features_path, 'w')\n",
        "h5f_data.create_dataset('dataset_1', data=np.array(features))\n",
        "\n",
        "h5f_label = h5py.File(labels_path, 'w')\n",
        "h5f_label.create_dataset('dataset_1', data=np.array(le_labels))\n",
        "\n",
        "h5f_data.close()\n",
        "h5f_label.close()\n",
        "\n",
        "print(\"[STATUS] features and labels saved..\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STATUS] features and labels saved..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxtqh-lQRyp9"
      },
      "source": [
        "# save model and weights\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTbptykORyxU",
        "outputId": "90ba3a36-697e-4b29-a8db-288e964433f2"
      },
      "source": [
        "# save model and weights\n",
        "model_json = model.to_json()\n",
        "with open(model_path + str(test_size) + \".json\", \"w+\") as json_file:\n",
        "  json_file.write(model_json)\n",
        "\n",
        "# save weights\n",
        "model.save_weights(model_path + str(test_size) + \".h5\")\n",
        "\n",
        "print(\"[STATUS] saved model and weights to disk..\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STATUS] saved model and weights to disk..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHfFNmgvWE2R"
      },
      "source": [
        "# load the user configs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpVf9EoKlngh"
      },
      "source": [
        "\n",
        "# load the user configs\n",
        "with open('/content/drive/MyDrive/covid19/config/config.json') as f:    \n",
        "  config = json.load(f)\n",
        "\n",
        "# config variables\n",
        "test_size       = config[\"test_size\"]\n",
        "seed            = config[\"seed\"]\n",
        "features_path   = config[\"features_path\"]\n",
        "labels_path     = config[\"labels_path\"]\n",
        "results         = config[\"results\"]\n",
        "classifier_path = config[\"classifier_path\"]\n",
        "train_path      = config[\"train_path\"]\n",
        "num_classes     = config[\"num_classes\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2m3aMZ4WMTc"
      },
      "source": [
        "# import features and labels\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHTvh-9BWLkD"
      },
      "source": [
        "# import features and labels\n",
        "h5f_data  = h5py.File(features_path, 'r')\n",
        "h5f_label = h5py.File(labels_path, 'r')\n",
        "\n",
        "features_string = h5f_data['dataset_1']\n",
        "labels_string   = h5f_label['dataset_1']\n",
        "\n",
        "features = np.array(features_string)\n",
        "labels   = np.array(labels_string)\n",
        "\n",
        "\n",
        "h5f_data.close()\n",
        "h5f_label.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcL3aqqjWYE2"
      },
      "source": [
        "# features Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl4A0X8nWX5N",
        "outputId": "41c0266f-7569-4cf0-9844-9cb8759e89f4"
      },
      "source": [
        "\n",
        "# Select features according to the k highest scores.\n",
        "n = int(features.shape[1]*7/100)\n",
        "fs = SelectKBest(score_func=f_classif, k=n)\n",
        "X_selected = fs.fit_transform(features, labels)\n",
        "\n",
        "# verify the shape of features and labels\n",
        "print(\"[INFO] features shape: {}\".format(X_selected.shape))\n",
        "print(\"[INFO] labels shape: {}\".format(labels.shape))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] features shape: (1125, 116)\n",
            "[INFO] labels shape: (1125,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ9D5_jUWqXA"
      },
      "source": [
        "# Splitting features into train and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSdn_i4yWePs",
        "outputId": "b85dfd57-451b-42ae-e63c-1f8d52d1badb"
      },
      "source": [
        "# split the training and testing data\n",
        "print(\"[INFO] training started...\")\n",
        "(XtrainData, XtestData, XtrainLabels, XtestLabels) = train_test_split(np.array(X_selected), np.array(labels),test_size=test_size,random_state=670)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training started...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abuceFr7XD4r"
      },
      "source": [
        "# use LighGBM Classification as the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmMaRxyzXV0O"
      },
      "source": [
        "# use LighGBM Classification as the model\n",
        "model = LGBMClassifier(max_depth= 3, learning_rate=0.24,n_estimators= 200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdDCD65IXPLx"
      },
      "source": [
        "# fit and predict model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGu8802-XLkc"
      },
      "source": [
        "# fit the model\n",
        "model.fit(XtrainData, XtrainLabels)\n",
        "\n",
        "# predict model\n",
        "preds = model.predict(XtestData)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YajuNvq7Xhs6"
      },
      "source": [
        "# confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYmdcUPzWZ6k"
      },
      "source": [
        "\n",
        "print(\"[INFO] Generate confusion matrix\")\n",
        "\n",
        "# confusion_matrix\n",
        "cm = confusion_matrix(XtestLabels, preds)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "sns.set(font_scale=1.4) # Adjust to fit\n",
        "\n",
        "labels = sorted(list(os.listdir(train_path)))\n",
        "sns.heatmap(cm,\n",
        "            yticklabels = labels,\n",
        "            xticklabels = labels,\n",
        "            annot=True,\n",
        "            cmap='binary'\n",
        "            )\n",
        "\n",
        "ax.tick_params(axis='both', which='major', labelsize=12)  # Adjust to fit\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUizDUkAXk7T"
      },
      "source": [
        "saved confusion matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q17jLKsXkyd"
      },
      "source": [
        "print(\"[INFO] saved confusion matrix as svg to disk..\")\n",
        "\n",
        "image_format = 'svg' # e.g .png, .svg, etc.\n",
        "image_name = '/content/drive/MyDrive/covid19/output/3class_matrix.svg'\n",
        "\n",
        "fig.savefig(image_name, format=image_format, dpi=1200)\n",
        "\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C08oBd2X0hV"
      },
      "source": [
        "# Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKpHIozbX0m-"
      },
      "source": [
        "result = {}\n",
        "\n",
        "Y_test = XtestLabels\n",
        "Y_pred = preds\n",
        "\n",
        "result[\"Accuracy score\"] =  metrics.accuracy_score(Y_test, Y_pred)\n",
        "result[\"confusion matrix\"] = metrics.confusion_matrix(Y_test, Y_pred)\n",
        "result[\"f1 score\"] = metrics.f1_score(Y_test, Y_pred, average=\"macro\")\n",
        "result[\"precision score\"] = metrics.precision_score(Y_test, Y_pred, average=\"macro\")\n",
        "result[\"Sensitivity\"] = result[\"confusion matrix\"][0,0] / (result[\"confusion matrix\"][0,0] + result[\"confusion matrix\"][0,1])\n",
        "result[\"Specifity\"] = result[\"confusion matrix\"][1,1] / (result[\"confusion matrix\"][1,0] + result[\"confusion matrix\"][1,1])\n",
        "\n",
        "print(f\"\\nAccuracy score :  %.4f\" % result[\"Accuracy score\"])\n",
        "print(f\"\\nconfusion matrix : \\n\" , result[\"confusion matrix\"])\n",
        "print(f\"\\nf1 score :  %.4f\" % result[\"f1 score\"])\n",
        "print(f\"\\nprecision score :  %.4f\" % result[\"precision score\"])\n",
        "print(f\"\\nSpecifity :  %.4f\" % result[\"Specifity\"])\n",
        "print(f\"\\nSensitivity :  %.4f\" % result[\"Sensitivity\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}